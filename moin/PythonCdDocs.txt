This page is intended to be used from the EducationalCd.

= Introductions =
 * [http:/docs/docs.python.org/Python-Docs-2.3.4/ Tutorial and Python/Library Reference 2.3.4]
 * [http:/docs/g2swaroop.net/byte/ A Byte of Python]
 * [http:/docs/diveintopython.org/diveintopython-5.4/html/ Dive into Python 5.4]
 * [http:/docs/www.ibiblio.org/ How to think like a Computer Scientist]
 * [http:/docs/beazley/intropy.pdf David Beazley's Intro to Python] ''pdf''
 * [http:/docs/beazley/advpy.pdf David Beazley's Advanced Python] ''pdf''

= Presentations =
 * [http://conferences.oreillynet.com/presentations/os2003/urner_kirby_final.ppt Kirby Urner's Python in Education] ''ppt''
 * [http://www.python.org/doc/essays/ppt/acm-cp4e/acm-cp4e.PPT Computer Programming for Everybody] ''ppt''

Are they anywhere else NOT in powerpoint format, but in html or pdf?

''If you open them in Powerpoint or Open Office, you can save them to HTML or PDF.''

= Essays =
 * [http:/docs/pythonology.com/whypython.html Why Python? by esr]

= Advanced =
 * [http:/docs/www.python.org/peps/pep-0000.html PEP index]

  * Python Docs, Essays, Free Python Books (IntroductoryBooks, AdvancedBooks?)
  * John Miller's Thesis - URL?

  * Docs, Tutorials and FAQs to non-core components (like PyGtk etc.)

= Python Wiki =

You said you wanted to mirror the Python wiki on the CD, here is a little script to suck the pages from the wiki to a folder:
{{{
#!python
import socket, os, sys, urllib2
socket.setdefaulttimeout(15)
from time import sleep

def suckwiki(pagelist, #url to plain text list of wiki pages
             rawpage, #url to raw wiki text of a page
             foldername="wikifiles", #name of folder to save files to
             sleeptime=1 #seconds to sleep between page accesses
             ):
    foldername = os.path.join(os.path.abspath(os.path.dirname(sys.argv[0])), foldername)
    if not os.path.exists(foldername): os.mkdir(foldername)
    opener = urllib2.build_opener()
    listrequest = urllib2.Request(pagelist)
    listresponse = opener.open(listrequest)
    sleep(sleeptime)
    for pagename in listresponse:
        pagename=pagename.strip().replace(' ','_20')
        print pagename
        fullpagename = rawpage % {'pagename':pagename}
        pagerequest = urllib2.Request(fullpagename)
        page = opener.open(pagerequest)
        f = open(os.path.join(foldername,pagename),"wb")
        f.write(page.read())
        f.close()
        page.close()
        sleep(sleeptime)

if __name__ == '__main__':
    pagelist = "http://www.python.org/cgi-bin/moinmoin/TitleIndex?action=titleindex"
    rawpage = r"http://www.python.org/cgi-bin/moinmoin/%(pagename)s?action=raw"
    foldername = "pythonwiki" #name of folder to save pages to
    suckwiki(pagelist,rawpage,foldername)
}}}
